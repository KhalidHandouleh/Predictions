{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Companies Bankruptcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Information:\n",
    "\n",
    "**The dataset is about bankruptcy prediction of Polish companies**\n",
    "\n",
    "The data was collected from Emerging Markets Information Service (EMIS, [Web Link]), which is a database containing information on emerging markets around the world. The bankrupt companies were analyzed in the period 2000-2012, while the still operating companies were evaluated from 2007 to 2013.\n",
    "\n",
    "Basing on the collected data five classification cases were distinguished, that depends on the forecasting period:\n",
    "\n",
    "- 1stYear: the data contains financial rates from 1st year of the forecasting period and corresponding class label that indicates bankruptcy status after 5 years. The data contains 7027 instances (financial statements), 271 represents bankrupted companies, 6756 firms that did not bankrupt in the forecasting period.\n",
    "\n",
    "- 2ndYear: the data contains financial rates from 2nd year of the forecasting period and corresponding class label that indicates bankruptcy status after 4 years. The data contains 10173 instances (financial statements), 400 represents bankrupted companies, 9773 firms that did not bankrupt in the forecasting period.\n",
    "\n",
    "- 3rdYear: the data contains financial rates from 3rd year of the forecasting period and corresponding class label that indicates bankruptcy status after 3 years. The data contains 10503 instances (financial statements), 495 represents bankrupted companies, 10008 firms that did not bankrupt in the forecasting period.\n",
    "\n",
    "- 4thYear: the data contains financial rates from 4th year of the forecasting period and corresponding class label that indicates bankruptcy status after 2 years. The data contains 9792 instances (financial statements), 515 represents bankrupted companies, 9277 firms that did not bankrupt in the forecasting period.\n",
    "\n",
    "- 5thYear: the data contains financial rates from 5th year of the forecasting period and corresponding class label that indicates bankruptcy status after 1 year. The data contains 5910 instances (financial statements), 410 represents bankrupted companies, 5500 firms that did not bankrupt in the forecasting period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features description\n",
    "\n",
    "- X1\tnet profit / total assets\n",
    "- X2\ttotal liabilities / total assets \n",
    "- X3\tworking capital / total assets \n",
    "- X4\tcurrent assets / short-term liabilities \n",
    "- X5\t[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365 \n",
    "- X6\tretained earnings / total assets \n",
    "- X7\tEBIT / total assets \n",
    "- X8\tbook value of equity / total liabilities \n",
    "- X9\tsales / total assets \n",
    "- X10\tequity / total assets \n",
    "- X11\t(gross profit + extraordinary items + financial expenses) / total assets \n",
    "- X12\tgross profit / short-term liabilities \n",
    "- X13\t(gross profit + depreciation) / sales \n",
    "- X14\t(gross profit + interest) / total assets \n",
    "- X15\t(total liabilities * 365) / (gross profit + depreciation) \n",
    "- X16\t(gross profit + depreciation) / total liabilities \n",
    "- X17\ttotal assets / total liabilities \n",
    "- X18\tgross profit / total assets \n",
    "- X19\tgross profit / sales \n",
    "- X20\t(inventory * 365) / sales \n",
    "- X21\tsales (n) / sales (n-1) \n",
    "- X22\tprofit on operating activities / total assets \n",
    "- X23\tnet profit / sales \n",
    "- X24\tgross profit (in 3 years) / total assets \n",
    "- X25\t(equity - share capital) / total assets \n",
    "- X26\t(net profit + depreciation) / total liabilities \n",
    "- X27\tprofit on operating activities / financial expenses \n",
    "- X28\tworking capital / fixed assets \n",
    "- X29\tlogarithm of total assets \n",
    "- X30\t(total liabilities - cash) / sales \n",
    "- X31\t(gross profit + interest) / sales \n",
    "- X32\t(current liabilities * 365) / cost of products sold \n",
    "- X33\toperating expenses / short-term liabilities \n",
    "- X34\toperating expenses / total liabilities \n",
    "- X35\tprofit on sales / total assets \n",
    "- X36\ttotal sales / total assets \n",
    "- X37\t(current assets - inventories) / long-term liabilities \n",
    "- X38\tconstant capital / total assets \n",
    "- X39\tprofit on sales / sales \n",
    "- X40\t(current assets - inventory - receivables) / short-term liabilities \n",
    "- X41\ttotal liabilities / ((profit on operating activities + depreciation) * (12/365)) \n",
    "- X42\tprofit on operating activities / sales \n",
    "- X43\trotation receivables + inventory turnover in days \n",
    "- X44\t(receivables * 365) / sales \n",
    "- X45\tnet profit / inventory \n",
    "- X46\t(current assets - inventory) / short-term liabilities \n",
    "- X47\t(inventory * 365) / cost of products sold \n",
    "- X48\tEBITDA (profit on operating activities - depreciation) / total assets \n",
    "- X49\tEBITDA (profit on operating activities - depreciation) / sales \n",
    "- X50\tcurrent assets / total liabilities \n",
    "- X51\tshort-term liabilities / total assets \n",
    "- X52\t(short-term liabilities * 365) / cost of products sold) \n",
    "- X53\tequity / fixed assets \n",
    "- X54\tconstant capital / fixed assets \n",
    "- X55\tworking capital \n",
    "- X56\t(sales - cost of products sold) / sales \n",
    "- X57\t(current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation) \n",
    "- X58\ttotal costs /total sales \n",
    "- X59\tlong-term liabilities / equity \n",
    "- X60\tsales / inventory \n",
    "- X61\tsales / receivables \n",
    "- X62\t(short-term liabilities *365) / sales \n",
    "- X63\tsales / short-term liabilities \n",
    "- X64\tsales / fixed assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading data objects from arff file\n",
    "data_objects = []\n",
    "for i in range(1,6):\n",
    "    i = str(i)\n",
    "    file_name = i+'year.arff'\n",
    "    data_objects.append(loadarff('./data/bankruptcy/'+i+'year.arff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataframes\n",
    "df_list = [pd.DataFrame.from_records(data=x[0]) for x in data_objects]\n",
    "companies = pd.concat(df_list, axis=0) \n",
    "column_names = ['x'+str(i) for i in range(1,65)] + ['bankrupt']\n",
    "column_names = {k:v for (k,v) in zip(companies.columns, column_names)}\n",
    "companies.rename(columns=column_names, inplace=True)\n",
    "companies['bankrupt'] = companies['bankrupt'].astype('int')\n",
    "companies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with missing values, this is just a quick way for demonstration purposes\n",
    "# in reality we must be more careful\n",
    "nas_by_feature = companies.isnull().sum(axis=0)\n",
    "# Droping features with more than 2000 missing values\n",
    "features_to_drop = nas_by_feature[nas_by_feature>2000].index\n",
    "companies.drop(features_to_drop, axis=1, inplace=True)\n",
    "companies.fillna(companies.median(), inplace=True)\n",
    "# No missing values!\n",
    "#companies.isnull().sum(axis=0).sum()\n",
    "companies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of an unbalanced classification problem\n",
    "# Normalize and *100 to show percentage of datapoints having each class\n",
    "100*companies['bankrupt'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Bankruptcy (using unbalanced classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CMatrix(CM, labels=['operating','bankrupt']):\n",
    "    df = pd.DataFrame(data=CM, index=labels, columns=labels)\n",
    "    df.index.name='TRUE'\n",
    "    df.columns.name='PREDICTION'\n",
    "    df.loc['Total'] = df.sum()\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing metrics DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(index=['accuracy','precision','recall'], \n",
    "                      columns=['NULL', 'LogisticReg', 'ClassTree', 'NaiveBayes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Accuracy**: the proportion of the total number of predictions that are correct\n",
    "- **Precision**: the proportion of positive predictions that are actually correct\n",
    "- **Recall**: the proportion of positive observed values correctly predicted as such\n",
    "\n",
    "**In this application:**\n",
    "- **Accuracy**: Overall, how often the classifier is correct\n",
    "- **Precision: Proportion of bankruptcy predictions that are actually correct**\n",
    "- **Recall**: Proportion of bankrupted companies that the classifier actually identifies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_name = 'bankrupt'\n",
    "robust_scaler = RobustScaler()\n",
    "X = companies.drop('bankrupt', axis=1)\n",
    "X = robust_scaler.fit_transform(X)\n",
    "y = companies[target_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Null model: always predict the most common category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = np.repeat(y_train.value_counts().idxmax(), y_test.size)\n",
    "metrics.loc['accuracy','NULL'] = accuracy_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['precision','NULL'] = precision_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['recall','NULL'] = recall_score(y_pred=y_pred_test, y_true=y_test)\n",
    "\n",
    "CM = confusion_matrix(y_pred=y_pred_test, y_true=y_test)\n",
    "CMatrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the estimator object (model)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2. Create an instance of the estimator\n",
    "# A lot of datapoints so to prevent overfitting use C=10 as regularization\n",
    "logistic_regression = LogisticRegression(C=10, n_jobs=-1, random_state=15)\n",
    "\n",
    "# 3. Use the trainning data to train the estimator\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "y_pred_test = logistic_regression.predict(X_test)\n",
    "metrics.loc['accuracy','LogisticReg'] = accuracy_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['precision','LogisticReg'] = precision_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['recall','LogisticReg'] = recall_score(y_pred=y_pred_test, y_true=y_test)\n",
    "\n",
    "CM = confusion_matrix(y_pred=y_pred_test, y_true=y_test)\n",
    "CMatrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Classification Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the estimator object (model)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 2. Create an instance of the estimator\n",
    "class_tree = DecisionTreeClassifier(max_depth=7, random_state=10)\n",
    "\n",
    "# 3. Use the trainning data to train the estimator\n",
    "class_tree.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "y_pred_test = class_tree.predict(X_test)\n",
    "metrics.loc['accuracy','ClassTree'] = accuracy_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['precision','ClassTree'] = precision_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['recall','ClassTree'] = recall_score(y_pred=y_pred_test, y_true=y_test)\n",
    "\n",
    "CM = confusion_matrix(y_pred=y_pred_test, y_true=y_test)\n",
    "CMatrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the estimator object (model). Use Gaussian because most features are continous\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 2. Create an instance of the estimator\n",
    "NBC = GaussianNB()\n",
    "# 3. Use the trainning data to train the estimator\n",
    "NBC.fit(X_train, y_train)\n",
    "# 4. Evaluate the model\n",
    "y_pred_test = NBC.predict(X_test)\n",
    "metrics.loc['accuracy','NaiveBayes'] = accuracy_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['precision','NaiveBayes'] = precision_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['recall','NaiveBayes'] = recall_score(y_pred=y_pred_test, y_true=y_test)\n",
    "\n",
    "CM = confusion_matrix(y_pred=y_pred_test, y_true=y_test)\n",
    "CMatrix(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "metrics.plot(kind='barh', ax=ax)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tree.predict(X_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predicting Bankrupcy: undersamplig the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select a small amount of data points from the majority class \n",
    "negative_cases = companies.loc[companies['bankrupt']==0].sample(n=4000)\n",
    "positive_cases = companies.loc[companies['bankrupt']==1]\n",
    "companies = pd.concat([negative_cases, positive_cases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies['bankrupt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create new datasets\n",
    "target_name = 'bankrupt'\n",
    "robust_scaler = RobustScaler()\n",
    "X = companies.drop('bankrupt', axis=1)\n",
    "X = robust_scaler.fit_transform(X)\n",
    "y = companies[target_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=125, stratify=y)"
   ]
  },
  {
   "source": [
    "# Redo all models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Null model: always predict the most common category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = np.repeat(y_train.value_counts().idxmax(), y_test.size)\n",
    "metrics.loc['accuracy','NULL'] = accuracy_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['precision','NULL'] = precision_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['recall','NULL'] = recall_score(y_pred=y_pred_test, y_true=y_test)\n",
    "\n",
    "CM = confusion_matrix(y_pred=y_pred_test, y_true=y_test)\n",
    "CMatrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the estimator object (model)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2. Create an instance of the estimator\n",
    "logistic_regression = LogisticRegression(C=10, n_jobs=-1, random_state=15)\n",
    "\n",
    "# 3. Use the trainning data to train the estimator\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "y_pred_test = logistic_regression.predict(X_test)\n",
    "metrics.loc['accuracy','LogisticReg'] = accuracy_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['precision','LogisticReg'] = precision_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['recall','LogisticReg'] = recall_score(y_pred=y_pred_test, y_true=y_test)\n",
    "\n",
    "CM = confusion_matrix(y_pred=y_pred_test, y_true=y_test)\n",
    "CMatrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Classification Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the estimator object (model)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 2. Create an instance of the estimator\n",
    "class_tree = DecisionTreeClassifier(max_depth=7, random_state=10)\n",
    "\n",
    "# 3. Use the trainning data to train the estimator\n",
    "class_tree.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "y_pred_test = class_tree.predict(X_test)\n",
    "metrics.loc['accuracy','ClassTree'] = accuracy_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['precision','ClassTree'] = precision_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['recall','ClassTree'] = recall_score(y_pred=y_pred_test, y_true=y_test)\n",
    "\n",
    "CM = confusion_matrix(y_pred=y_pred_test, y_true=y_test)\n",
    "CMatrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the estimator object (model)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 2. Create an instance of the estimator\n",
    "NBC = GaussianNB()\n",
    "# 3. Use the trainning data to train the estimator\n",
    "NBC.fit(X_train, y_train)\n",
    "# 4. Evaluate the model\n",
    "y_pred_test = NBC.predict(X_test)\n",
    "metrics.loc['accuracy','NaiveBayes'] = accuracy_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['precision','NaiveBayes'] = precision_score(y_pred=y_pred_test, y_true=y_test)\n",
    "metrics.loc['recall','NaiveBayes'] = recall_score(y_pred=y_pred_test, y_true=y_test)\n",
    "\n",
    "CM = confusion_matrix(y_pred=y_pred_test, y_true=y_test)\n",
    "CMatrix(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "metrics.plot(kind='barh', ax=ax)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get feature names and feature importance from Classification Tree\n",
    "feature_names = companies.drop('bankrupt', axis=1).columns\n",
    "feat_importance = pd.Series(data=class_tree.feature_importances_, index=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance.sort_values(ascending=False)[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 most important features: \n",
    "1. gross profit (in 3 years) / total assets\n",
    "2. (current assets - inventory) / short-term liabilities\n",
    "3.  [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def individual_prediction(company_data):\n",
    "    company_data = robust_scaler.transform(company_data.values.reshape(1, -1))\n",
    "    prediction = class_tree.predict(company_data)[0]\n",
    "    proba = class_tree.predict_proba(company_data)[0][0]\n",
    "    #print(proba)\n",
    "    #print(type(proba))\n",
    "    if prediction == 0:\n",
    "        return \"Will be operating in 5 years (with {:0.2f}% chance)\".format(100*proba)\n",
    "    else:\n",
    "        return \"Will be bankrupt in 5 years (with {:0.2f}% chance)\".format(100*(1-proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data = OrderedDict([\n",
    "    (\"x1\", 0.033162), (\"x2\", 0.22283), (\"x3\", 0.37), (\"x4\", 4.4679), (\"x5\", 209.34), \n",
    "    (\"x6\", 0.0), (\"x7\", 0.046205), (\"x8\", 3.4878), (\"x9\", 0.64932), (\"x10\", 0.77717), \n",
    "    (\"x11\", 0.059273), (\"x12\", 0.43214), (\"x13\", 0.18681), (\"x14\", 0.046205), (\"x15\", 670.48), \n",
    "    (\"x16\", 0.54438), (\"x17\", 4.4878), (\"x18\", 0.046205), (\"x19\", 0.071159), (\"x20\", 23.396), \n",
    "    (\"x22\", 0.013612), (\"x23\", 0.051072), (\"x24\", 0.5), (\"x25\", 0.58292), (\"x26\", 0.48585), \n",
    "    (\"x28\", 0.70994), (\"x29\", 3.9291), (\"x30\", -0.033028), (\"x31\", 0.091285), (\"x32\", 61.596), \n",
    "    (\"x33\", 5.9257), (\"x34\", 2.8434), (\"x35\", 0.015735), (\"x36\", 0.64932), (\"x38\", 0.89308), \n",
    "    (\"x39\", 0.024234), (\"x40\", 2.3258), (\"x41\", 0.083729), (\"x42\", 0.020964), (\"x43\", 128.75), \n",
    "    (\"x44\", 105.35), (\"x46\", 4.0786), (\"x47\", 23.978), (\"x48\", -0.061485), (\"x49\", -0.094692), \n",
    "    (\"x50\", 2.1439), (\"x51\", 0.10692), (\"x52\", 0.16876), (\"x53\", 1.488), (\"x54\", 1.7099), \n",
    "    (\"x55\", 3149.5), (\"x56\", 0.024234), (\"x57\", 0.04267), (\"x58\", 0.93354), (\"x59\", 0.14914), \n",
    "    (\"x61\", 3.4646), (\"x62\", 60.103), (\"x63\", 6.0729), (\"x64\", 1.2432)\n",
    "])\n",
    "\n",
    "new_company_data = pd.Series(company_data)\n",
    "individual_prediction(new_company_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_bankrupt_company = companies[companies['bankrupt']==1].iloc[3].drop('bankrupt')\n",
    "individual_prediction(known_bankrupt_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}